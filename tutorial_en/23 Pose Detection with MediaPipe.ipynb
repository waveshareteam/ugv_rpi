{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c4fd43-5f29-4730-809e-636c10579e89",
   "metadata": {},
   "source": [
    "# Pose Detection with MediaPipe\n",
    "\n",
    "This section describes how to implement pose detection using MediaPipe + OpenCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970758cf-56c0-434d-8b73-6b87811afcc8",
   "metadata": {},
   "source": [
    "## What is MediaPipe?\r\n",
    "\n",
    "MediaPipe is an open-source framework developed by Google for building machine learning-based multimedia processing applications. It provides a set of tools and libraries for processing video, audio, and image data, and applies machine learning models to achieve various functionalities such as pose estimation, gesture recognition, and face detection. MediaPipe is designed to offer efficient, flexible, and easy-to-use solutions, enabling developers to quickly build a variety of multimedia processing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deddf12-7e89-4e1f-b6de-fe343f6743e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparation\n",
    "\n",
    "Since the product automatically runs the main program at startup, which occupies the camera resource, this tutorial cannot be used in such situations. You need to terminate the main program or disable its automatic startup before restarting the robot.\n",
    "\n",
    "It's worth noting that because the robot's main program uses multi-threading and is configured to run automatically at startup through crontab, the usual method sudo killall python typically doesn't work. Therefore, we'll introduce the method of disabling the automatic startup of the main program here.\n",
    "\n",
    "### Terminate the Main Program\n",
    "\n",
    "1. Click the \"+\" icon next to the tab for this page to open a new tab called \"Launcher.\"\n",
    "2. Click on \"Terminal\" under \"Other\" to open a terminal window.\n",
    "3. Type bash into the terminal window and press Enter.\n",
    "4. Now you can use the Bash Shell to control the robot.\n",
    "5. Enter the command: crontab -e.\n",
    "6. If prompted to choose an editor, enter 1 and press Enter to select nano.\n",
    "7. After opening the crontab configuration file, you'll see the following two lines:\n",
    "> @reboot ~/ugv_pt_rpi/ugv-env/bin/python ~/ugv_pt_rpi/app.py >> ~/ugv.log 2>&1\n",
    ">\n",
    ">@reboot /bin/bash ~/ugv_pt_rpi/start_jupyter.sh >> ~/jupyter_log.log 2>&1\n",
    "\n",
    "8. Add a # character at the beginning of the line with ……app.py >> …… to comment out this line.\n",
    "> #@reboot ~/ugv_pt_rpi/ugv-env/bin/python ~/ugv_pt_rpi/app.py >> ~/ugv.log 2>&1\n",
    ">\n",
    ">@reboot /bin/bash ~/ugv_pt_rpi/start_jupyter.sh >> ~/jupyter_log.log 2>&1\n",
    "\n",
    "9. Press Ctrl + X in the terminal window to exit. It will ask you Save modified buffer? Enter Y and press Enter to save the changes.\n",
    "10. Reboot the device. Note that this process will temporarily close the current Jupyter Lab session. If you didn't comment out ……start_jupyter.sh >>…… in the previous step, you can still use Jupyter Lab normally after the robot reboots (JupyterLab and the robot's main program app.py run independently). You may need to refresh the page.\n",
    "11. One thing to note is that since the lower machine continues to communicate with the upper machine through the serial port, the upper machine may not start up properly during the restart process due to the continuous change of serial port levels. Taking the case where the upper machine is a Raspberry Pi, after the Raspberry Pi is shut down and the green LED is constantly on without the green LED blinking, you can turn off the power switch of the robot, then turn it on again, and the robot will restart normally.\n",
    "12. Enter the reboot command: sudo reboot.\n",
    "13. After waiting for the device to restart (during the restart process, the green LED of the Raspberry Pi will blink, and when the frequency of the green LED blinking decreases or goes out, it means that the startup is successful), refresh the page and continue with the remaining part of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1a36d1-fa2c-4701-92bb-1168f4d114f8",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "The following code block can be executed directly:\n",
    "\n",
    "1. Select the code block below.\n",
    "2. Press Shift + Enter to run the code block.\n",
    "3. Watch the real-time video window.\n",
    "4. Press STOP to close the real-time video and release the camera resources.\n",
    "\n",
    "### If the real-time camera view is not visible during execution\n",
    "\n",
    "- Click on Kernel - Shut down all kernels above.\n",
    "- Close the current chapter tab and reopen it.\n",
    "- Click STOP to release the camera resources, then run the code block again.\n",
    "- Reboot the device.\n",
    "\n",
    "### Features\n",
    "\n",
    "When the code block runs normally, MediaPipe will automatically mark the joints of human body when there is a face in the frame.ace in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6490793-4079-4f0f-b555-c06e21a93505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Import the OpenCV library for image processing\n",
    "import imutils, math  # Auxiliary libraries for image processing and mathematical operations\n",
    "from picamera2 import Picamera2  # Library to access the Raspberry Pi Camera\n",
    "from IPython.display import display, Image  # Library to display images in Jupyter Notebook\n",
    "import ipywidgets as widgets  # Library for creating interactive widgets, such as buttons\n",
    "import threading  # Library for creating new threads for asynchronous execution of tasks\n",
    "import mediapipe as mp  # Import the MediaPipe library for pose detection\n",
    "\n",
    "# Create a \"Stop\" button that users can click to stop the video stream\n",
    "# ================\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Description',\n",
    "    icon='square' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# Initialize MediaPipe's drawing tools and pose detection model\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "# MediaPipe Pose Detection\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, \n",
    "                    model_complexity=1, \n",
    "                    smooth_landmarks=True, \n",
    "                    min_detection_confidence=0.5, \n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "# Define the display function to process video frames and perform pose detection\n",
    "def view(button):\n",
    "    # If you are using a CSI camera, uncomment the picam2 related code below, \n",
    "    # and comment out the camera related code.\n",
    "    # This is because the latest version of OpenCV (4.9.0.80) no longer supports CSI cameras, \n",
    "    # and you need to use picamera2 to capture camera images.\n",
    "    \n",
    "    # picam2 = Picamera2()  # Create an instance of Picamera2\n",
    "    # picam2.configure(picam2.create_video_configuration(main={\"format\": 'XRGB8888', \"size\": (640, 480)}))  # Configure camera parameters\n",
    "    # picam2.start()  # Start the camera\n",
    "\n",
    "    camera = cv2.VideoCapture(-1) \n",
    "    camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    display_handle=display(None, display_id=True)  # Create a display handle to update the displayed image\n",
    "    \n",
    "    while True:\n",
    "        #frame = picam2.capture_array()\n",
    "        _, frame = camera.read()\n",
    "        # frame = cv2.flip(frame, 1) # if your camera reverses your image\n",
    "\n",
    "        # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        results = pose.process(img) # Use MediaPipe to process the image and get pose detection results\n",
    "\n",
    "         # If pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Convert the image from RGB to BGR for drawing\n",
    "            mpDraw.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)  # Use MediaPipe's drawing tools to draw pose landmarks and connections\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert the image back from BGR to RGB for display\n",
    "            \n",
    "        _, frame = cv2.imencode('.jpeg', frame)  # Encode the processed frame into JPEG format\n",
    "        display_handle.update(Image(data=frame.tobytes()))  # Update the displayed image\n",
    "        if stopButton.value==True:  # Check if the \"Stop\" button is pressed\n",
    "            # picam2.close()  # If so, close the camera\n",
    "            cv2.release() # If yes, close the camera\n",
    "            display_handle.update(None)  # Clear the displayed content\n",
    "\n",
    "# Display the \"Stop\" button and start a thread to run the display function\n",
    "display(stopButton)\n",
    "thread = threading.Thread(target=view, args=(stopButton,))\n",
    "thread.start()  # Start the thread\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
